{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_new_videos(r'CONFIG_FILE_PATH', [r'NEW_VIDEO_PATHS'], copy_videos = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the project path and video directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_paths(r'PROJECT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the source project to the target project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_projects(r'CONFIG_FILE_PATH_OF_THE_TARGET_PROJECT',\n",
    "               r'CONFIG_FILE_PATH_OF_THE_SOURCE_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_projects2(r'TARGET_PROJECT_PATH',\n",
    "                r'SOURCE_PROJECT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_project(r'SOURCE_PROJECT_PATH',\n",
    "             r'DESTINATION_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_project2(r'SOURCE_PROJECT_PATH',\n",
    "              r'DESTINATION_DIRECTORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DLC Data index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dlc_data_ndex(r'DLC_DATA_FOLDER_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy DLC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dlc_data(r'SOURCE_DLC_DATA_FOLDER_PATH',\n",
    "              r'DESTINATION_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dlc_data2(r'SOURCE_DLC_DATA_FOLDER_PATH',\n",
    "               r'DESTINATION_DIRECTORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Run all below before calling them*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabcut.create_project import add_new_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the project path and video directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_paths(prj_path):\n",
    "    cnf_path = Path(prj_path)/'config.yaml'\n",
    "    vid_dir = Path(prj_path)/'videos'\n",
    "    \n",
    "    \n",
    "    cnf = auxiliaryfunctions.read_config(cnf_path)\n",
    "    cnf['project_path'] = str(prj_path)\n",
    "\n",
    "    old_vid_sets, new_vid_sets = cnf['video_sets'], {}\n",
    "    videos = old_vid_sets.keys()\n",
    "    for i in videos:\n",
    "        new_vid_sets[str(vid_dir/Path(i).name)] = old_vid_sets[i]\n",
    "    cnf['video_sets'] = new_vid_sets\n",
    "\n",
    "    auxiliaryfunctions.write_config(cnf_path, cnf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the source project to the target project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_projects(trg_cnf_path, src_cnf_path):\n",
    "    trg_cnf = auxiliaryfunctions.read_config(trg_cnf_path)\n",
    "    trg_scr = trg_cnf['scorer']\n",
    "    trg_prj_path = trg_cnf['project_path']\n",
    "    trg_videos = trg_cnf['video_sets'].keys()\n",
    "    trg_vid_stems = [Path(_).stem for _ in trg_videos]\n",
    "\n",
    "    src_cnf = auxiliaryfunctions.read_config(src_cnf_path)\n",
    "    src_scr = src_cnf['scorer']\n",
    "    src_prj_path = src_cnf['project_path']\n",
    "    src_videos = src_cnf['video_sets'].keys()\n",
    "    src_vid_stems = [Path(_).stem for _ in src_videos]\n",
    "    \n",
    "    # Intersection of \n",
    "    # Stems of videos in the target project and \n",
    "    # Stems of videos in the source project, excluding those without CollectedData_scorer.csv \n",
    "    ints = list(set(trg_vid_stems) &\n",
    "                set(_ for _ in src_vid_stems \n",
    "                    if os.path.exists(Path(src_prj_path)/'labeled-data'/Path(_)/('CollectedData_'+src_scr+'.csv'))))\n",
    "    for i in ints:\n",
    "        trg_dat_dir = Path(trg_prj_path)/'labeled-data'/Path(i)\n",
    "        src_dat_dir = Path(src_prj_path)/'labeled-data'/Path(i)\n",
    "    \n",
    "        if not os.path.exists(trg_dat_dir/('CollectedData_'+trg_scr+'.csv')):\n",
    "            trg_bod_parts = trg_cnf['bodyparts']\n",
    "            new_coll_dat = [['scorer'] + [trg_scr] * 2 * len(trg_bod_parts),\n",
    "                            ['bodyparts'] + [_i for _i in trg_bod_parts for _j in range(2)],\n",
    "                            ['coords'] + ['x', 'y'] * len(trg_bod_parts)]\n",
    "            pd.DataFrame(new_coll_dat).to_csv(trg_dat_dir/('CollectedData_'+trg_scr+'.csv'), header=False, index=False)\n",
    "            \n",
    "        trg_coll_dat = pd.read_csv(trg_dat_dir/('CollectedData_'+trg_scr+'.csv'), header=None, index_col=0)\n",
    "        src_coll_dat = pd.read_csv(src_dat_dir/('CollectedData_'+src_scr+'.csv'), header=None, index_col=0, skiprows=3)\n",
    "    \n",
    "        mrg = pd.concat([trg_coll_dat, src_coll_dat])\n",
    "        # Regarding duplicates, keep those form target collected data\n",
    "        mrg = mrg[~mrg.index.duplicated()]\n",
    "        mrg.to_csv(trg_dat_dir/('CollectedData_'+trg_scr+'.csv'), header=False)\n",
    "    \n",
    "        for j in mrg[3:].index:\n",
    "            shutil.copy2(Path(src_prj_path)/Path(j), trg_dat_dir)\n",
    "    \n",
    "        # Converse .csv to .h5; adapted from utils/conversioncode.py\n",
    "        data=pd.read_csv(trg_dat_dir/('CollectedData_'+trg_scr+'.csv'))\n",
    "    \n",
    "        #nlines,numcolumns=data.shape\n",
    "    \n",
    "        orderofbpincsv=list(data.values[0,1:-1:2])\n",
    "        imageindex=list(data.values[2:,0])       \n",
    "    \n",
    "        #assert(len(orderofbpincsv)==len(cfg['bodyparts']))\n",
    "        print(orderofbpincsv)\n",
    "        print(trg_cnf['bodyparts'])\n",
    "    \n",
    "        #TODO: test len of images vs. len of imagenames for another sanity check\n",
    "    \n",
    "        index = pd.MultiIndex.from_product([[trg_scr], orderofbpincsv, ['x', 'y']],names=['scorer', 'bodyparts', 'coords'])\n",
    "        frame = pd.DataFrame(np.array(data.values[2:,1:],dtype=float), columns = index, index = imageindex)\n",
    "    \n",
    "        frame.to_hdf(trg_dat_dir/('CollectedData_'+trg_scr+'.h5'), key='df_with_missing', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_projects2(trg_prj_path, src_prj_path):\n",
    "    update_paths(trg_prj_path)\n",
    "    update_paths(src_prj_path)\n",
    "    merge_project(Path(trg_prj_path)/'config.yaml',\n",
    "                  Path(src_prj_path)/'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_project(src, dst):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "        \n",
    "        \n",
    "    src_cnf_path = Path(src)/'config.yaml'\n",
    "    dst_cnf_path = Path(dst)/'config.yaml'\n",
    "\n",
    "    cnf = auxiliaryfunctions.read_config(src_cnf_path)\n",
    "\n",
    "    scr = cnf['scorer']\n",
    "    videos = cnf['video_sets'].keys()\n",
    "    vid_stems = [Path(_).stem for _ in videos]\n",
    "    \n",
    "    \n",
    "    # Copy labelled data\n",
    "    print('    Labelled data')\n",
    "    if not os.path.exists(Path(dst)/'labeled-data'):\n",
    "        os.makedirs(Path(dst)/'labeled-data')\n",
    "\n",
    "    for i in vid_stems:\n",
    "        src_dat_dir = Path(src)/'labeled-data'/Path(i)\n",
    "        dst_dat_dir = Path(dst)/'labeled-data'/Path(i)\n",
    "        if not os.path.exists(dst_dat_dir):\n",
    "            os.makedirs(dst_dat_dir)\n",
    "        \n",
    "        if os.path.exists(src_dat_dir/('CollectedData_'+scr+'.csv')):\n",
    "            coll_dat = pd.read_csv(src_dat_dir/('CollectedData_'+scr+'.csv'), header=None, index_col=0, skiprows=3)\n",
    "    \n",
    "            for j in coll_dat.index:\n",
    "                shutil.copy2(Path(src)/Path(j), dst_dat_dir)\n",
    "\n",
    "            shutil.copy2(src_dat_dir/('CollectedData_'+scr+'.csv'), dst_dat_dir)\n",
    "            shutil.copy2(src_dat_dir/('CollectedData_'+scr+'.h5'), dst_dat_dir)\n",
    "        \n",
    "    \n",
    "    # Copy videos\n",
    "    print('    Videos')\n",
    "    if not os.path.exists(Path(dst)/'videos'):\n",
    "        os.makedirs(Path(dst)/'videos') \n",
    "    \n",
    "    for i in videos:\n",
    "        shutil.copy2(i, Path(dst)/'videos')\n",
    "        \n",
    "    \n",
    "    # Write and update config.yaml\n",
    "    print('    config.yaml')\n",
    "    cnf['iteration'] = 0\n",
    "    auxiliaryfunctions.write_config(dst_cnf_path, cnf)\n",
    "    \n",
    "    update_paths(dst)\n",
    "    \n",
    "    # Create dlc-models and training-datasets folders\n",
    "    if not os.path.exists(Path(dst)/'dlc-models'):\n",
    "        os.makedirs(Path(dst)/'dlc-models')\n",
    "    if not os.path.exists(Path(dst)/'training-datasets'):\n",
    "        os.makedirs(Path(dst)/'training-datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_project2(src, dst_dir):\n",
    "    copy_project(src,\n",
    "                Path(dst_dir)/Path(src).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DLC Data index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dlc_data_ndex(dlc_dat):\n",
    "    # vid: Video\n",
    "    # prj: Project\n",
    "    # labd_frm_nmb: Number of Labelled Frames\n",
    "    # h5: .h5\n",
    "    # labd_vid: Labelled Video\n",
    "    ind = []\n",
    "\n",
    "    prj_paths = [_ for _ in Path(dlc_dat).iterdir() if _.is_dir()]\n",
    "    for i in prj_paths:\n",
    "        update_paths(i)\n",
    "    \n",
    "        cnf_path = i/'config.yaml'\n",
    "        cnf = auxiliaryfunctions.read_config(cnf_path)\n",
    "        scr = cnf['scorer']\n",
    "        vid_sets = cnf['video_sets']\n",
    "    \n",
    "        for j in vid_sets:\n",
    "            vid_stem = Path(j).stem\n",
    "        \n",
    "            # Number of Labelled Frames\n",
    "            coll_dat_path = i/'labeled-data'/vid_stem/('CollectedData_'+scr+'.csv')\n",
    "            if not os.path.exists(coll_dat_path):\n",
    "                labd_frm_nmb = 'Not labelled'\n",
    "            else:\n",
    "                coll_dat = pd.read_csv(coll_dat_path, header=None, skiprows=3)\n",
    "                labd_frm_nmb = coll_dat.shape[0]\n",
    "        \n",
    "            # .h5\n",
    "            h5_paths = sorted((i/'videos').glob(vid_stem+'*.h5'))\n",
    "            if not h5_paths:\n",
    "                h5 = 'Not analysed'\n",
    "            else:\n",
    "                h5_t_names = []\n",
    "                for k in h5_paths:\n",
    "                    # Iteration: Best trained comes first\n",
    "                    it = k.stem.split('_')[-1]\n",
    "                    h5_t_names.append({'it': it, 'name': k.name})\n",
    "                h5_t_names = sorted(h5_t_names, key=itemgetter('it'), reverse=True)\n",
    "                h5 = h5_t_names[0]['name']\n",
    "                \n",
    "            # Labelled Video\n",
    "            if h5 == 'Not analysed':\n",
    "                labd_vid = 'Not analysed'\n",
    "            elif not os.path.exists(i/'videos'/(h5.split('.h5')[0]+'_labeled.mp4')):\n",
    "                labd_vid = 'Not created'\n",
    "            else:\n",
    "                labd_vid = h5.split('.h5')[0]+'_labeled.mp4'\n",
    "        \n",
    "            ind.append({'vid': Path(j).name, 'prj': Path(i).name, 'labd_frm_nmb': labd_frm_nmb, 'h5': h5, 'labd_vid': labd_vid})\n",
    "\n",
    "    ind = pd.DataFrame(ind)\n",
    "    ind = ind.rename(columns={'vid': 'Video',\n",
    "                              'prj': 'Project',\n",
    "                              'labd_frm_nmb': 'Number of Labelled Frames',\n",
    "                              'h5': '.h5',\n",
    "                              'labd_vid': 'Labelled Video'})\n",
    "    ind.to_csv(Path(dlc_dat)/'index.csv', columns=['Video',\n",
    "                                                   'Project',\n",
    "                                                   'Number of Labelled Frames',\n",
    "                                                   '.h5',\n",
    "                                                   'Labelled Video'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy DLC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dlc_data(src, dst):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "        \n",
    "        \n",
    "    create_dlc_data_ndex(src)\n",
    "    \n",
    "    \n",
    "    ind = pd.read_csv(Path(src)/'index.csv', index_col=1)\n",
    "\n",
    "    prjs = ind.index.drop_duplicates()\n",
    "    for i in prjs:\n",
    "        print('Copying Project: ' + i)\n",
    "        # Copy project\n",
    "        copy_project2(Path(src)/i, dst)\n",
    "    \n",
    "        # Copy .h5 and labelled videos\n",
    "        print('    .h5 and labelled videos')\n",
    "        ind_curr_prjs = ind.loc[i]\n",
    "    \n",
    "        # When the project contains only one video\n",
    "        if type(ind_curr_prjs['.h5']) is str:\n",
    "            h5 = ([ind_curr_prjs['.h5']] \n",
    "                  if ind_curr_prjs['.h5'] != 'Not analysed'\n",
    "                  else [])\n",
    "        else:\n",
    "            h5 = [_ for _ in ind_curr_prjs['.h5'] if _ != 'Not analysed']\n",
    "    \n",
    "        if type(ind_curr_prjs['Labelled Video']) is str:\n",
    "            labd_vid = ([ind_curr_prjs['Labelled Video']] \n",
    "                        if ind_curr_prjs['Labelled Video'] != 'Not analysed' and ind_curr_prjs['Labelled Video'] != 'Not created'\n",
    "                        else [])\n",
    "        else:\n",
    "            labd_vid = [_ for _ in ind_curr_prjs['Labelled Video'] if _ != 'Not analysed' and _ != 'Not created']\n",
    "    \n",
    "        for j in h5 + labd_vid:\n",
    "            shutil.copy2(Path(src)/i/'videos'/j, Path(dst)/i/'videos')\n",
    "        \n",
    "        # Copy the example video\n",
    "        print('    Example video')\n",
    "        ex_vid = sorted(Path(src).glob(i+'.*'))\n",
    "        shutil.copy2(ex_vid[0], dst)\n",
    "    \n",
    "    print('Copying index.csv')\n",
    "    shutil.copy2(Path(src)/'index.csv', dst)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dlc_data2(src, dst_dir):\n",
    "    copy_dlc_data(src,\n",
    "                  Path(dst_dir)/Path(src).name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
