{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from time import time\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7cf6df45012a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/donghan/DeepLabCut/data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Return the file name with extention of .h5, which contain the data of coordination axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/donghan/DeepLabCut/data/\")\n",
    "filenames = glob.glob('*.h5') \n",
    "#Return the file name with extention of .h5, which contain the data of coordination axis\n",
    "f = []\n",
    "for filename in filenames:\n",
    "    f = h5py.File(filename, 'r')\n",
    "    start = filename.find('10') \n",
    "    #Find the string that start with \"10\"\n",
    "    end = filename.find(' rotated', start) \n",
    "    #Return the string with end of \" rotated\", aims to name the file\n",
    "    csvfile = []\n",
    "    with pd.HDFStore(filename, 'r') as d:\n",
    "        df = d.get(list(f.keys())[0])\n",
    "        df.to_csv(filename[start:end] + '.csv') \n",
    "        #Automaticaly change to unique file name with specific mouse number\n",
    "        csvfile.append(filename[start:end] + '.csv')\n",
    "for i in csvfile:\n",
    "    data = pd.read_csv(i, skiprows = 2) \n",
    "    #Skip the rows of scorer and bodyparts\n",
    "    move_data = data.loc[260:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoWriter(task, filename, outputName, corrX, corrY, distX, distY, displayVideo = False):\n",
    "    \n",
    "    '''\n",
    "    Task: Takes video as input and returns its capturing and output file. \n",
    "    \n",
    "    If task is edited, then corrX and corrY is the vertex of the cropped video edge. \n",
    "    '''\n",
    "\n",
    "    # Capture video\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    # Read video frame by frame\n",
    "    # Extract original video frame features\n",
    "    sz = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # Make a directory to store the processed videos\n",
    "    path = \"./\" + task\n",
    "    try:  \n",
    "        os.mkdir(path)\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "    except OSError:  \n",
    "        pass\n",
    "    \n",
    "\n",
    "    #Automatically name the processed videos  \n",
    "    file = \"./\" + task + \"/\" + outputName\n",
    "    if task == \"edited\":\n",
    "        out = cv2.VideoWriter(file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, (distY, distX)) \n",
    "        # Another option: cv2.VideoWriter_fourcc(*'XVID')\n",
    "    else:\n",
    "        out = cv2.VideoWriter(file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, sz)\n",
    "\n",
    "    return cap,out\n",
    "    \n",
    "def videoEditer(filename, outputName, corrX, corrY, distX, distY, displayVideo = False):\n",
    "\n",
    "    '''\n",
    "    Task: Crop videos to actural mouse moving edge\n",
    "    \n",
    "    PARAMETERS:\n",
    "    video: file that await for writting\n",
    "    \n",
    "    filename: video that need to be trim\n",
    "    \n",
    "    outputName: filename of output video\n",
    "    \n",
    "    corrX: coordinates of the start point in X\n",
    "    \n",
    "    corrY: coordinates of the start point in Y\n",
    "    \n",
    "    dist: cropped video is a square, as long as the coordinates of the start point is defined, the other\n",
    "    three vertex points are clear. \n",
    "\n",
    "    '''\n",
    "    # Calculate the other three points' coordinate\n",
    "    corrX1 = corrX + distX\n",
    "    corrY1 = corrY + distY\n",
    "\n",
    "    video = videoWriter(\"edited\", filename, outputName, corrX, corrY, distX, distY, displayVideo)\n",
    "    cap = video[0] \n",
    "    out = video[1]                  \n",
    "    frameCnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    # Not capturing a video\n",
    "    if (cap.isOpened() == False): \n",
    "          print(\"Unable to read video\")\n",
    "    count = 1\n",
    "    # Read videos and rotate by certain degrees\n",
    "    while(cap.isOpened()):\n",
    "        # Flip for truning(fliping) frames of video\n",
    "        ret,img = cap.read()\n",
    "        try:\n",
    "            img2 = img[corrX:corrX1, corrY:corrY1]\n",
    "            out.write(img2)\n",
    "            if displayVideo == True:\n",
    "                cv2.imshow('edited video',img2) \n",
    "            if count == frameCnt:\n",
    "                print (filename, 'successfully ', \"edited!\")\n",
    "                break\n",
    "            else:\n",
    "                count += 1\n",
    "            k=cv2.waitKey(30) & 0xff\n",
    "            #once you inter Esc capturing will stop\n",
    "            if k==27:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    \n",
    "def getCoord(data):\n",
    "    '''\n",
    "    Task: Obtaining the coordinates of cropped points\n",
    "    '''\n",
    "    xMax = max((data['x']).astype(int))\n",
    "    xMin = min((data['x']).astype(int))\n",
    "    yMax = max((data['y']).astype(int))\n",
    "    yMin = min((data['y']).astype(int))\n",
    "    \n",
    "    lengthX = xMax - xMin\n",
    "    lengthY = yMax - yMin\n",
    "    \n",
    "#     if yMax - yMin < xMax - xMin:\n",
    "#         length = yMax - yMin\n",
    "#     else:\n",
    "#         length = xMax - xMin\n",
    "    \n",
    "    \n",
    "    return xMin, yMin, lengthX, lengthY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoEditer('1034 SI_B, Aug 15, 13 7 49.mp4', \"cropTest.mp4\", 10,10,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, lengthX, lengthY = getCoord(move_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(move_data['y'], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "move_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, lengthX, lengthY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoEditer('1034 SI_B, Aug 15, 13 7 49.mp4', \"cropTest.mp4\", x, y, lengthX, lengthY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-01dbc80d502b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test2.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "p = cv2.imread(\"test2.jpg\")\n",
    "p[:,:,:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cv2.imread(\"test2.jpg\")\n",
    "p = p[:,:,::-1]\n",
    "# p = cv2.cvtColor(p[:,:,::-1], cv2.COLOR_BGR2GRAY)\n",
    "# p = cv2.cvtColor(p, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(\"test3.jpg\",p[0:200,0:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1f832a2f4988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m460\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m275\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "from moviepy.video.fx import crop\n",
    "crop(p, x1=50, y1=60, x2=460, y2=275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "# load the image and compute the ratio of the old height\n",
    "# to the new height, clone it, and resize it\n",
    "image = cv2.imread(\"test2.jpg\")\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    " \n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "# show the original image and the edge detected image\n",
    "print(\"STEP 1: Edge Detection\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    " \n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    " \n",
    "    # if our approximated contour has four points, then we\n",
    "    # can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    " \n",
    " # show the contour (outline) of the piece of paper\n",
    "print(\"STEP 2: Find contours of paper\")\n",
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 1) * ratio)\n",
    " \n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "T = threshold_local(warped, 11, offset = 10, method = \"gaussian\")\n",
    "warped = (warped > T).astype(\"uint8\") * 255\n",
    " \n",
    "# show the original and scanned images\n",
    "print(\"STEP 3: Apply perspective transform\")\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = videoWriter(\"crop\", '1034 SI_B, Aug 15, 13 7 49.mp4', \"cropTest.mp4\")\n",
    "cap = video[0]\n",
    "out = video[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
