{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-d755c68c6a9a>, line 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-d755c68c6a9a>\"\u001b[0;36m, line \u001b[0;32m71\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/donghan/DeepLabCut/data/\")\n",
    "#Change to your own video data directory\n",
    "\n",
    "def videoWriter(task, filename, outputName, corrX = None, corrY = None, dist = 320, displayVideo = False):\n",
    "    \n",
    "    '''\n",
    "    Task: Takes video as input and returns its capturing and output file. \n",
    "    \n",
    "    If task is edited, then corrX and corrY is the vertex of the cropped video edge. \n",
    "    '''\n",
    "\n",
    "    # Capture video\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    # Read video frame by frame\n",
    "    # Extract original video frame features\n",
    "    sz = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # Make a directory to store the processed videos\n",
    "    path = \"./\" + task\n",
    "    try:  \n",
    "        os.mkdir(path)\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "    except OSError:  \n",
    "        pass\n",
    "\n",
    "\n",
    "    #Automatically name the processed videos  \n",
    "    file = \"./\" + task + \"/\" + outputName\n",
    "    if task == \"edited\":\n",
    "        out = cv2.VideoWriter(file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, (dist, dist)) \n",
    "        # Another option: cv2.VideoWriter_fourcc(*'XVID')\n",
    "    else:\n",
    "        out = cv2.VideoWriter(file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, sz)\n",
    "\n",
    "    return cap,out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def walkingPath(data, filename, outputName, color, displayVideo = False):\n",
    "    '''\n",
    "    Graph the walking path of the mouse movement\n",
    "    '''\n",
    "    \n",
    "    head = zip(round(data['x']).astype(int), round(data['y']).astype(int))\n",
    "    tail = zip(round(data['x.1']).astype(int), round(data['y.1']).astype(int))\n",
    "        \n",
    "    #cap: Read video\n",
    "    #out: Write video\n",
    "    video = videoWriter(\"walking path\", filename, outputName, displayVideo)\n",
    "    cap = video[0]\n",
    "    out = video[1]\n",
    "\n",
    "    # Get the frames count of video in order to break the loop when it reaches the last frame\n",
    "    frameCnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if (cap.isOpened() == False): \n",
    "          print(\"Unable to read video\")\n",
    "    count = 1\n",
    "    while(cap.isOpened()):\n",
    "        try:\n",
    "            ret,img = cap.read()\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(\"/home/donghan/DeepLabCut/data/1.jpg\")\n",
    "\n",
    "image[100:200][100:200] = np.array([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([207, 175, 139], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/donghan/Neural-Decoding-Project\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"test.jpg\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
