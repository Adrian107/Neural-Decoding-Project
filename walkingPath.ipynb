{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "os.chdir(\"/home/donghan/DeepLabCut/data/\")\n",
    "\n",
    "filenames = glob.glob('*.h5') \n",
    "#Return the file name with extention of .h5, which contain the data of coordination axis\n",
    "f = []\n",
    "for filename in filenames:\n",
    "    f = h5py.File(filename, 'r')\n",
    "    start = filename.find('10') \n",
    "    #Find the string that start with \"10\"\n",
    "    end = filename.find(' rotated', start) \n",
    "    #Return the string with end of \" rotated\", aims to name the file\n",
    "    csvfile = []\n",
    "    with pd.HDFStore(filename, 'r') as d:\n",
    "        df = d.get(list(f.keys())[0])\n",
    "        df.to_csv(filename[start:end] + '.csv') \n",
    "        #Automaticaly change to unique file name with specific mouse number\n",
    "        csvfile.append(filename[start:end] + '.csv')\n",
    "for i in csvfile:\n",
    "    data = pd.read_csv(i, skiprows = 2) \n",
    "    #Skip the rows of scorer and bodyparts\n",
    "    move_data = data.loc[200:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1034 SI_B, Aug 15, 13 7 49DeepCut_resnet50_ReachingMar12shuffle1_800.h.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Color define, could be different RGB\n",
    "WHITE = (255,255,255)\n",
    "BLACK = (0,0,0)\n",
    "\n",
    "os.chdir(\"/home/donghan/DeepLabCut/data/\")\n",
    "#Change to your own video data directory\n",
    "\n",
    "def videoWriter(task, filename, outputName, corrX = None, corrY = None, dist = 320, displayVideo = False):\n",
    "    \n",
    "    '''\n",
    "    Task: Takes video as input and returns its capturing and output file. \n",
    "    \n",
    "    If task is edited, then corrX and corrY is the vertex of the cropped video edge. \n",
    "    '''\n",
    "\n",
    "    # Capture video\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    # Read video frame by frame\n",
    "    # Extract original video frame features\n",
    "    sz = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # Make a directory to store the processed videos\n",
    "    path = \"./\" + task\n",
    "    try:  \n",
    "        os.mkdir(path)\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "    except OSError:  \n",
    "        pass\n",
    "\n",
    "\n",
    "    #Automatically name the processed videos  \n",
    "    file = \"./\" + task + \"/\" + outputName\n",
    "    if task == \"edited\":\n",
    "        out = cv2.VideoWriter(file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, (dist, dist)) \n",
    "        # Another option: cv2.VideoWriter_fourcc(*'XVID')\n",
    "    else:\n",
    "        out = cv2.VideoWriter(file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, sz)\n",
    "\n",
    "    return cap,out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def walkingPath(data, filename, outputName, color, displayVideo = False):\n",
    "    '''\n",
    "    Graph the walking path of the mouse movement\n",
    "    '''\n",
    "    \n",
    "    head = zip(round(data['x']).astype(int), round(data['y']).astype(int))\n",
    "    tail = zip(round(data['x.1']).astype(int), round(data['y.1']).astype(int))\n",
    "        \n",
    "    #cap: Read video\n",
    "    #out: Write video\n",
    "    video = videoWriter(\"walking path\", filename, outputName, displayVideo)\n",
    "    cap = video[0]\n",
    "    out = video[1]\n",
    "\n",
    "    # Get the frames count of video in order to break the loop when it reaches the last frame\n",
    "    frameCnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if (cap.isOpened() == False): \n",
    "          print(\"Unable to read video\")\n",
    "    count = 1\n",
    "    while(cap.isOpened()):\n",
    "        try:\n",
    "            for x, y in tail:\n",
    "                ret,img = cap.read()\n",
    "                img[x][y] = BLACK\n",
    "            out.write(img)\n",
    "            \n",
    "            # Break the loop when the last frame has been rotated\n",
    "            if count == frameCnt:\n",
    "                print (filename, 'successfully ', \"added field of view!!!\")\n",
    "                break\n",
    "            else:\n",
    "                count += 1\n",
    "        except:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "walkingPath(data, \"1034 SI_B, Aug 15, 13 7 49.mp4\", \"walkingPathTest.mp4\", BLACK)\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(\"/home/donghan/DeepLabCut/data/1.jpg\")\n",
    "\n",
    "image[100:200][100:200] = np.array([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = zip(round(data['x.1']).astype(int), round(data['y.1']).astype(int))\n",
    "for i, j in tail:\n",
    "    image[i][j] = (0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/donghan/Neural-Decoding-Project\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"test.jpg\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
